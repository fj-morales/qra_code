{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re \n",
    "import csv\n",
    "import torch\n",
    "import sys\n",
    "# sys.path.append('qra_cod')\n",
    "from utils.meter import AUCMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Options\n",
    "\n",
    "# debugging mode\n",
    "\n",
    "debug = 'yes'\n",
    "build_index_flag = 'yes'\n",
    "# N of workers for multiprocessing used grid_search\n",
    "pool_size = 20\n",
    "\n",
    "data_split = 'test'\n",
    "workdir = './baselines/workdir/'\n",
    "# qloc = './qra_data/android/'\n",
    "qloc = './qra_data/askubuntu/'\n",
    "galago_loc='./baselines/galago-3.10-bin/bin/'\n",
    "\n",
    "build_index_flag = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sc(text):\n",
    "###    text = re.sub('[.,?;*!%^&_+():-\\[\\]{}]', '', text.replace('\"', '').replace('/', '').replace('\\\\', '').replace(\"'\", '').strip())\n",
    "##    text = re.sub('[\\[\\]{}.,?;*!%^&_+():-]', '', text.replace('\"', '').replace('/', '').replace('\\\\', '').replace(\"'\", '').strip()) # DeepPaper method\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text) # My method\n",
    "###     text = text.rstrip('.?')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_questions(filename):\n",
    "    with gzip.open(filename, 'rt') as tsv_in:\n",
    "        qreader = csv.reader(tsv_in, delimiter = '\\t')\n",
    "        questions = {}\n",
    "#         q_dict = {}\n",
    "        for q in qreader:\n",
    "            question = {}\n",
    "            if 'quora' in filename:\n",
    "                print('quora')\n",
    "            elif 'sprint' in filename:\n",
    "                print('quora')\n",
    "            else:\n",
    "#                 question['id'] = q[0]\n",
    "#                 q_dict[q[0]] = q[1] + ' ' + q[2]\n",
    "                question['title'] = q[1]\n",
    "                question['text'] = q[2]\n",
    "                questions[q[0]]=(dict(question))\n",
    "#         return [questions, q_dict]\n",
    "        return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trectext_format(questions):\n",
    "    trec_questions = {}\n",
    "    for key, q in questions.items():\n",
    "        doc = '<DOC>\\n' + \\\n",
    "              '<DOCNO>' + key + '</DOCNO>\\n' + \\\n",
    "              '<TITLE>' + q['title'] + '</TITLE>\\n' + \\\n",
    "              '<TEXT>' + q['text'] + '</TEXT>\\n' + \\\n",
    "              '</DOC>\\n'\n",
    "        trec_questions[key] = doc\n",
    "    return trec_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trectext(trec_questions, filename):\n",
    "# Generate file to index\n",
    "#     with gzip.open(filename,'wt', encoding='utf-8') as f_out:\n",
    "    with gzip.open(filename,'wt') as f_out:\n",
    "        for key, value in trec_questions.items():\n",
    "            f_out.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(index_input, index_loc):\n",
    "    if build_index_flag == 'yes':\n",
    "        return\n",
    "# Build corpus index \n",
    "    if not os.path.exists(index_loc):\n",
    "            os.makedirs(index_loc) \n",
    "    index_loc_param = '--indexPath=' + index_loc\n",
    "    galago_parameters = [galago_loc + 'galago', 'build', '--stemmer+krovetz']\n",
    "    galago_parameters.append('--inputPath+' + index_input)\n",
    "    galago_parameters.append(index_loc_param)\n",
    "    print(galago_parameters)\n",
    "\n",
    "    index_proc = subprocess.Popen(galago_parameters,\n",
    "            stdout=subprocess.PIPE, shell=False)\n",
    "    (out, err) = index_proc.communicate()\n",
    "    print(out.decode(\"utf-8\"))\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dups(dups_file):\n",
    "    with open(dups_file, 'rt') as dups_in:\n",
    "        dup_reader = csv.reader(dups_in, delimiter = ' ')\n",
    "        dup_list = []\n",
    "        dup_dict = {}\n",
    "        for dup in dup_reader:\n",
    "            dup_dict['doc_id'] = dup[0]\n",
    "            dup_dict['dup_id'] = dup[1]\n",
    "            if 'pos' in dups_file:\n",
    "                dup_dict['label'] = 1\n",
    "            elif 'neg' in dups_file:\n",
    "                dup_dict['label'] = 0\n",
    "            dup_list.append(dict(dup_dict))\n",
    "    return dup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dup_files(dups_file):\n",
    "    with open(dups_file, 'rt') as dups_in:\n",
    "        dup_reader = csv.reader(dups_in, delimiter = ' ')\n",
    "        dup_list = []\n",
    "        for dup in dup_reader:\n",
    "#             print(dup)\n",
    "            if dup[0] in dup_dict.keys():\n",
    "                dup_dict[dup[0]].append(dup[1])\n",
    "            else:\n",
    "                dup_dict[dup[0]] = [dup[1]]\n",
    "    return dup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries_file(questions, q_dup_pos, filename):\n",
    "    queries_list = []\n",
    "    queries_dict = {}\n",
    "    query = {}\n",
    "    for query in q_dup_pos:\n",
    "        key = query['doc_id']\n",
    "        q = questions[key]\n",
    "        text = remove_sc(q['title'] + ' ' + q['text']) #Join title and text \n",
    "        query['number'] = key\n",
    "#         query['text'] = '#stopword(' + text + ')'\n",
    "        query['text'] = '(' + text + ')'\n",
    "        queries_list.append(dict(query))\n",
    "    queries_dict['queries'] = queries_list\n",
    "    # with open(filename, 'wt', encoding='utf-8') as q_file:\n",
    "    with open(filename, 'wt') as q_file: #encoding option not working on python 2.7\n",
    "        json.dump(queries_dict, q_file, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Return top 1 bm25 scored question = 'duplicated' question\n",
    "# def get_bm25_docs(queries_file, q_all, q_dup_pos, q_dup_neg, index_loc, b_val=0.75, k_val=1.2):\n",
    "#     index_loc_param = '--index=' + index_loc  \n",
    "#     b=' --b=' + str(b_val)\n",
    "#     k=' --k=' + str(k_val)\n",
    "    \n",
    "#     command = galago_loc + 'galago threaded-batch-search --threadCount=50 --verbose=false \\\n",
    "#          --casefold=true --requested=1000 ' + \\\n",
    "#          index_loc_param + ' --scorer=bm25' + \\\n",
    "#          b + \\\n",
    "#          k + \\\n",
    "#          '   ' + \\\n",
    "#          queries_file + ' | cut -d\" \" -f1,3,5 > all_results.txt'\n",
    "#         # cut -d\" \" -f1,3' # for the document \n",
    "        \n",
    "#     print(command)\n",
    "# #     command = command.encode('utf-8')\n",
    "# #     galago_bm25_exec = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, encoding='utf-8')\n",
    "#     galago_bm25_exec = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "#     (out, err) = galago_bm25_exec.communicate()\n",
    "#     ids_docs = out.splitlines()\n",
    "# #     print(ids_docs)\n",
    "#     question = {}\n",
    "#     bm25_scores = []\n",
    "# #     return ids_docs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #     for doc_id, dup_docs in q_dup_pos.items():\n",
    "# #         dup_scores = {}\n",
    "# #         docs_scores = {}\n",
    "# #         for doc in ids_docs:\n",
    "# #             if (doc_id == doc.split(' ')[0]):\n",
    "# #                 docs_scores[doc.split(' ')[1]]=doc.split(' ')[2]\n",
    "# # #         [docs_scores[doc.split(' ')[1]]=doc.split(' ')[2] for doc in ids_docs if (doc_id == doc.split(' ')[0])]\n",
    "# #         for dup_doc in dup_docs:\n",
    "# #             dup_scores['q_id'] = doc_id\n",
    "# #             dup_scores['dup_id'] = dup_doc\n",
    "# #             if dup_doc in docs_scores:\n",
    "# #                 dup_scores['bm25_score'] = docs_scores[dup_doc]\n",
    "# #             else:\n",
    "# #                 dup_scores['bm25_score'] = '0'\n",
    "# # #             print(dup_scores)\n",
    "# #             bm25_scores.append(dict(dup_scores))\n",
    "# # #             if dup_doc in <lista positiva de documentos duplicados>\n",
    "# # #                 dup_scores['label'] = 1\n",
    "# # #             else:\n",
    "# # #                 dup_scores['label'] = 0\n",
    "        \n",
    "# # #     for dup_pair in q_dup_pos:\n",
    "# # #         key = dup_pair[0]\n",
    "# # #         question = {}\n",
    "# # #         q_temp = q_all[key]\n",
    "# # #         question['body'] = q_temp['title'] + ' ' + q_temp['text']\n",
    "# # #         question['id'] = key  \n",
    "# # #         doc_options = [doc.split(' ')[1] for doc in ids_docs if (key == doc.split(' ')[0])]\n",
    "# # #         for doc_id in doc_options:\n",
    "# # #             print(key, ' ', doc_id)\n",
    "# # #             if not doc_id == key:\n",
    "# # #                 documents = doc_id\n",
    "# # #                 break\n",
    "# # # #         print(documents)\n",
    "# # #         question['documents'] = documents\n",
    "# # #         bm25_docs.append(dict(question))\n",
    "# #     return bm25_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top 1 bm25 scored question = 'duplicated' question\n",
    "def get_bm25_docs(queries_file, q_all, index_loc, b_val=0.75, k_val=1.2):\n",
    "    index_loc_param = '--index=' + index_loc  \n",
    "    b=' --b=' + str(b_val)\n",
    "    k=' --k=' + str(k_val)\n",
    "    \n",
    "    command = galago_loc + 'galago threaded-batch-search --threadCount=50 --verbose=false \\\n",
    "         --casefold=true --requested=50000 ' + \\\n",
    "         index_loc_param + ' --scorer=bm25' + \\\n",
    "         b + \\\n",
    "         k + \\\n",
    "         '   ' + \\\n",
    "         queries_file + ' | cut -d\" \" -f1,3,5 '\n",
    "#          queries_file + ' | cut -d\" \" -f1,3,5 > all_results.txt'\n",
    "        # cut -d\" \" -f1,3' # for the document \n",
    "        \n",
    "    print(command)\n",
    "#     command = command.encode('utf-8')\n",
    "#     galago_bm25_exec = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True, encoding='utf-8')\n",
    "    galago_bm25_exec = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "    (out, err) = galago_bm25_exec.communicate()\n",
    "    all_scores = out.splitlines()\n",
    "#     print(ids_docs)\n",
    "    \n",
    "#     return ids_docs\n",
    "    all_dict = {}\n",
    "    for doc in all_scores:\n",
    "        key_pair = doc.split(' ')[0] + '_' + doc.split(' ')[1]\n",
    "        all_dict[key_pair] = doc.split(' ')[2]\n",
    "    bm25_scores = [] \n",
    "    i = 0\n",
    "    for query_dict in q_all:\n",
    "        i += 1\n",
    "        key_pair = query_dict['doc_id'] + '_' + query_dict['dup_id']\n",
    "        try: \n",
    "            query_dict['score'] = all_dict[key_pair]\n",
    "        except:\n",
    "            query_dict['score'] = 0\n",
    "        if i % 10000 == 0:\n",
    "            print('processed: ', i)\n",
    "        bm25_scores.append(dict(query_dict))\n",
    "    return bm25_scores   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_work_dirs():\n",
    "    if debug == 'yes':\n",
    "        print('yes')\n",
    "        # Execute remove sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = qloc.split('/')[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(workdir):\n",
    "    os.makedirs(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_prefix = workdir + dataset_name[0]\n",
    "index_loc = loc_prefix + '_index'\n",
    "questions_file = loc_prefix + '_questions' + '.gz'\n",
    "queries_file = loc_prefix + '_queries'\n",
    "trectext_file = loc_prefix + '_trectext.gz'\n",
    "index_input = trectext_file\n",
    "dups_file_pos = qloc + data_split + '.pos.txt'\n",
    "dups_file_neg = qloc + data_split + '.neg.txt'\n",
    "corpus_file = qloc + 'corpus.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = read_questions(corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions['14853']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions['6693']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "q_dup_pos = read_dups(dups_file_pos)\n",
    "print(len(q_dup_pos))\n",
    "q_dup_neg = read_dups(dups_file_neg)\n",
    "print(len(q_dup_neg))\n",
    "q_all = q_dup_pos + q_dup_neg \n",
    "trec_questions = trectext_format(questions)\n",
    "save_trectext(trec_questions, trectext_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': '615465', 'dup_id': '8653', 'label': 1},\n",
       " {'doc_id': '833376', 'dup_id': '377050', 'label': 1}]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dup_pos[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries_file(questions, q_dup_pos, queries_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_index(index_input, index_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./baselines/galago-3.10-bin/bin/galago threaded-batch-search --threadCount=50 --verbose=false          --casefold=true --requested=50000 --index=./baselines/workdir/askubuntu_index --scorer=bm25 --b=0.75 --k=1.2   ./baselines/workdir/askubuntu_queries | cut -d\" \" -f1,3,5 \n",
      "('processed: ', 10000)\n",
      "('processed: ', 20000)\n",
      "('processed: ', 30000)\n",
      "('processed: ', 40000)\n",
      "('processed: ', 50000)\n",
      "('processed: ', 60000)\n",
      "('processed: ', 70000)\n",
      "('processed: ', 80000)\n",
      "('processed: ', 90000)\n",
      "('processed: ', 100000)\n"
     ]
    }
   ],
   "source": [
    "bm25_docs = get_bm25_docs(queries_file, q_all, index_loc, b_val=0.75, k_val=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': '615465',\n",
       "  'dup_id': '8653',\n",
       "  'label': 1,\n",
       "  'number': '615465',\n",
       "  'score': '0.31930030',\n",
       "  'text': '(SSH stays open remotely   When connecting to a server   is there a way to keep the SSH console open once disconnected   Or is there a program that does that   and that lets me connect back into where I left   This situation can happen for instance if I start a simple manual backup using cp from towards that takes  1h   I may not be able to wait and have to close the connection   but I still want my command to finish and I may even login later and check the result message   My current method achieving this  )'}]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_docs[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [doc['score'] for doc in bm25_docs]\n",
    "scores = np.asarray(scores)\n",
    "scores = scores.astype(np.float)\n",
    "labels = [doc['label'] for doc in bm25_docs]\n",
    "labels = np.asarray(labels)\n",
    "labels = labels.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3193003 , 0.41495868, 0.88025809, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6964324\n"
     ]
    }
   ],
   "source": [
    "auc_meter = AUCMeter()\n",
    "auc_meter.add(scores, labels)\n",
    "auc05_score = auc_meter.value(0.05)\n",
    "print(auc05_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
